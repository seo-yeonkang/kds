import torch
import re
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer
from peft import PeftModel
from typing import Optional

class M2M100TranslationService:
    def __init__(self, model_path: str):
        """
        Args:
            model_path: íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì´ ì €ì¥ëœ ê²½ë¡œ
        """
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_path = model_path
        self.model = None
        self.tokenizer = None
        self._load_model()
    
    def _load_model(self):
        """ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë”©"""
        print(f"ğŸ”„ ëª¨ë¸ ë¡œë”©: {self.model_path}")
        
        # ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”©
        base_model = M2M100ForConditionalGeneration.from_pretrained(
            "facebook/m2m100_418M",
            torch_dtype=torch.float16,
            device_map="auto"
        )
        
        # LoRA ëª¨ë¸ ë¡œë”©
        self.model = PeftModel.from_pretrained(base_model, self.model_path)
        self.model.eval()
        
        # í† í¬ë‚˜ì´ì € ë¡œë”©py 
        self.tokenizer = M2M100Tokenizer.from_pretrained(self.model_path)
        
        print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ (device: {self.device})")
    
    def _detect_language(self, text: str) -> str:
        """ê°„ë‹¨í•œ ì–¸ì–´ ê°ì§€ (í•œê¸€/ì¤‘êµ­ì–´)"""
        # í•œê¸€ ë¬¸ì íŒ¨í„´
        korean_pattern = re.compile(r'[ê°€-í£]')
        # ì¤‘êµ­ì–´ ë¬¸ì íŒ¨í„´  
        chinese_pattern = re.compile(r'[\u4e00-\u9fff]')
        
        korean_count = len(korean_pattern.findall(text))
        chinese_count = len(chinese_pattern.findall(text))
        
        if korean_count > chinese_count:
            return "ko"
        else:
            return "zh"
    
    def translate(self, text: str, source_lang: Optional[str] = None, target_lang: Optional[str] = None) -> str:
        """
        í…ìŠ¤íŠ¸ ë²ˆì—­
        
        Args:
            text: ë²ˆì—­í•  í…ìŠ¤íŠ¸
            source_lang: ì†ŒìŠ¤ ì–¸ì–´ ("ko" ë˜ëŠ” "zh", Noneì´ë©´ ìë™ ê°ì§€)
            target_lang: íƒ€ê²Ÿ ì–¸ì–´ ("ko" ë˜ëŠ” "zh", Noneì´ë©´ ìë™ ê²°ì •)
        
        Returns:
            ë²ˆì—­ëœ í…ìŠ¤íŠ¸
        """
        if not text or not text.strip():
            return text
        
        # ì–¸ì–´ ìë™ ê°ì§€
        if source_lang is None:
            source_lang = self._detect_language(text)
        
        # íƒ€ê²Ÿ ì–¸ì–´ ìë™ ê²°ì •
        if target_lang is None:
            target_lang = "zh" if source_lang == "ko" else "ko"
        
        # ê°™ì€ ì–¸ì–´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if source_lang == target_lang:
            return text
        
        try:
            # í† í°í™”
            inputs = self.tokenizer(
                text,
                return_tensors="pt",
                max_length=128,
                truncation=True,
                padding=True
            ).to(self.device)
            
            # ë²ˆì—­ ìƒì„±
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=128,
                    num_beams=3,
                    length_penalty=1.0,
                    early_stopping=True,
                    do_sample=False
                )
            
            # ë””ì½”ë”©
            translated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ì¶œë ¥ì— í¬í•¨ëœ ê²½ìš° ì œê±°
            if text in translated:
                translated = translated.replace(text, "").strip()
            
            return translated if translated else text
            
        except Exception as e:
            print(f"âŒ ë²ˆì—­ ì˜¤ë¥˜: {e}")
            return text  # ì˜¤ë¥˜ ì‹œ ì›ë³¸ ë°˜í™˜

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ë²ˆì—­ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    translator = M2M100TranslationService("translation_m2m") #lora ê²½ë¡œë¡œ ë³€ê²½
    
    # í…ŒìŠ¤íŠ¸
    korean_text = "ê·¼ë¡œê³„ì•½ì„œì—ì„œ ì´ˆê³¼ê·¼ë¬´ìˆ˜ë‹¹ì€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ë‚˜ìš”?"
    chinese_text = "åŠ ç­è´¹æ˜¯æ€ä¹ˆè®¡ç®—çš„ï¼Ÿ"
    
    # í•œêµ­ì–´ â†’ ì¤‘êµ­ì–´
    result1 = translator.translate(korean_text)
    print(f"ğŸ‡°ğŸ‡· â†’ ğŸ‡¨ğŸ‡³: {korean_text}")
    print(f"ê²°ê³¼: {result1}")
    
    # ì¤‘êµ­ì–´ â†’ í•œêµ­ì–´  
    result2 = translator.translate(chinese_text)
    print(f"ğŸ‡¨ğŸ‡³ â†’ ğŸ‡°ğŸ‡·: {chinese_text}")
    print(f"ê²°ê³¼: {result2}")
    
    # ëª…ì‹œì  ì–¸ì–´ ì§€ì •
    result3 = translator.translate("ä½ å¥½", source_lang="zh", target_lang="ko")
    print(f"ëª…ì‹œì  ë²ˆì—­: {result3}")